{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./OriginalData/Berlin/pardok-wp16.xml', './OriginalData/Berlin/pardok-wp18.xml', './OriginalData/Berlin/pardok-wp19.xml', './OriginalData/Berlin/pardok-wp14.xml', './OriginalData/Berlin/pardok-wp17.xml', './OriginalData/Berlin/pardok-wp12.xml', './OriginalData/Berlin/pardok-wp15.xml', './OriginalData/Berlin/pardok-wp11.xml', './OriginalData/Berlin/pardok-wp13.xml']\n"
     ]
    }
   ],
   "source": [
    "# First define the following parameters in this cell\n",
    "# Then run the entire notebook\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "## folder name where a list of xml files are stored\n",
    "## these will be concatenated to one event log file for the given process type\n",
    "\n",
    "## filename of xml input\n",
    "folderPath = \"./OriginalData/Berlin\"\n",
    "\n",
    "\n",
    "files = [join(folderPath, f) for f in listdir(folderPath) if isfile(join(folderPath, f))]\n",
    "\n",
    "print(files)\n",
    "\n",
    "\n",
    "## VTyp to take as process type\n",
    "#vtyp = \"Antrag\"\n",
    "vtyp = \"Gesetz\"\n",
    "\n",
    "## output filename\n",
    "outputFilename = './all-data-xes/berlin-gesetz' + '.xes'\n",
    "#outputFilename = './WP16_BadenWÃ¼rttemberg_' + vtyp + '.xes'\n",
    "#outputFilename = './WP6_Brandenburg_' + vtyp + '.xes'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into dict\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import pprint\n",
    "import pandas as pd\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "processes = []\n",
    "for file in files:\n",
    "    with open(file) as xml_file:\n",
    "        data = xmltodict.parse(xml_file.read())\n",
    "        dataVorgaenge = data[\"Export\"][\"Vorgang\"] # this has the actual data\n",
    "        processes.extend(dataVorgaenge) # append all processes to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VNr', 'VFunktion', 'VID', 'ReihNr', 'VTyp', 'VTypL', 'VSys', 'VSysL',\n",
      "       'VIR', 'Nebeneintrag', 'Dokument'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "VTyp\n",
      "Anfrage                75958\n",
      "Antrag                 10180\n",
      "Beschlussempfehlung       56\n",
      "Debatte                14815\n",
      "Gesetz                  2267\n",
      "Wahl                     605\n",
      "Name: VTyp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get all processes into a dataframe\n",
    "processesDF = pd.DataFrame.from_dict(processes)\n",
    "\n",
    "print(processesDF.keys())\n",
    "print(\"\\n\")\n",
    "\n",
    "groupedByType = processesDF.groupby(['VTyp'])\n",
    "print(groupedByType['VTyp'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsOfVorgaenge = groupedByType.get_group(vtyp)[\"Dokument\"]\n",
    "vSysLOfVorgange = groupedByType.get_group(vtyp)[\"VSysL\"]\n",
    "vSysOfVorgange = groupedByType.get_group(vtyp)[\"VSys\"]\n",
    "vorgangNebeneintraege = groupedByType.get_group(vtyp)[\"Nebeneintrag\"]\n",
    "\n",
    "# for a Vorgang there are several Deskriptoren stored in several Nebeneintraege\n",
    "# -> get that information per Vorgang\n",
    "vorgangDeskriptoren = []\n",
    "for nebeneintraege in vorgangNebeneintraege:\n",
    "    if type(nebeneintraege) is not list:\n",
    "        if nebeneintraege is not dict:\n",
    "            deskriptoren = []\n",
    "        else:\n",
    "            deskriptoren = [nebeneintraege.get(\"Desk\", None)]\n",
    "    else:\n",
    "        deskriptoren = [obj.get(\"Desk\", None) for obj in nebeneintraege]\n",
    "\n",
    "    vorgangDeskriptoren.append([x for x in deskriptoren if x is not None])\n",
    "\n",
    "allDocs = []\n",
    "\n",
    "# add trace id to each document\n",
    "# so that the documents can then be single events that belong to a specific trace in an event log\n",
    "\n",
    "for idx, vorgang in enumerate(docsOfVorgaenge):\n",
    "    helperX = vorgang\n",
    "    if type(vorgang) is dict:\n",
    "        helperX = [vorgang]\n",
    "        \n",
    "    dokTypLOfFirstDoc = None\n",
    "    for i, doc in enumerate(helperX):\n",
    "        # add case id column to each document\n",
    "        # call it case:concept:name as this is the name for pm4py transformation into XES format\n",
    "        doc['case:concept:name'] = idx\n",
    "        \n",
    "        # if it is the first document in a Vorgang, then set the dokTypLOfFirstDoc - this could also be used to see what type of process a Vorgang is\n",
    "        if (i == 0):\n",
    "            dokTypLOfFirstDoc = doc.get(\"DokTypL\", None)\n",
    "        \n",
    "        doc['case:DokTypLFirstDoc'] = dokTypLOfFirstDoc\n",
    "            \n",
    "        doc['case:VSys'] = vSysOfVorgange.iloc[idx]\n",
    "        doc['case:VSysL'] = vSysLOfVorgange.iloc[idx]\n",
    "        doc['case:VorgangsDeskriptoren'] = vorgangDeskriptoren[idx]\n",
    "\n",
    "        # if there is no value for a key, replace it with \"none\"\n",
    "        # or if a list value has none values\n",
    "        for key, value in doc.items():\n",
    "            if value is None: \n",
    "                doc.update({key: \"none\"})\n",
    "            if type(value) is list:\n",
    "                doc.update({key: [x if x is not None else \"none\" for x in value]})\n",
    "        \n",
    "        # for grouping reasons also sort all other entries that can be sorted\n",
    "        doc_sortedEntries = {key: sorted(value) if type(value) is list else value for key, value in doc.items()}\n",
    "        \n",
    "        # now add this doc as a row \n",
    "        allDocs.append(doc)\n",
    "\n",
    "\n",
    "\n",
    "# turn docs into data frame, so each row is a document now\n",
    "df = pd.DataFrame(allDocs)\n",
    "#print(df.keys())\n",
    "\n",
    "# turn date string into date time object\n",
    "df[\"DokDat\"] = pd.to_datetime(df['DokDat'], format='%d.%m.%Y')\n",
    "#print(df[\"DokDat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phillmann/.local/lib/python3.8/site-packages/pm4py/utils.py:96: UserWarning: Some rows of the Pandas data frame have been removed because of empty case IDs, activity labels, or timestamps to ensure the correct functioning of PM4Py's algorithms.\n",
      "  warnings.warn(\"Some rows of the Pandas data frame have been removed because of empty case IDs, activity labels, or timestamps to ensure the correct functioning of PM4Py's algorithms.\")\n",
      "/home/phillmann/.local/lib/python3.8/site-packages/pm4py/utils.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[constants.CASE_CONCEPT_NAME] = df[constants.CASE_CONCEPT_NAME].astype(\"string\")\n",
      "/home/phillmann/.local/lib/python3.8/site-packages/pm4py/utils.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[xes_constants.DEFAULT_NAME_KEY] = df[xes_constants.DEFAULT_NAME_KEY].astype(\"string\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a20848bc074554b14811704618439a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/2267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use pm4py to create XES file\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "#eventlog = df.copy(deep=True)\n",
    "#eventlog.rename(columns={'DokDat': 'time:timestamp', 'DokTypL': 'concept:name'}, inplace=True)\n",
    "\n",
    "event_log = pm4py.format_dataframe(df, case_id='case:concept:name', activity_key='DokTypL', timestamp_key='DokDat')\n",
    "#start_activities = pm4py.get_start_activities(event_log)\n",
    "#end_activities = pm4py.get_end_activities(event_log)\n",
    "#print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "pm4py.write_xes(event_log, outputFilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
